import pytz
from datetime import datetime
from models.entities import Article, IAProcessedData, Noticia, ProcessStatusDTO, IALogModel
import repository.proceso_repository as repository
from services.ia_models_service import IAService
from services.scraping.scraping import extraer_noticias_elperiodico, extraer_noticias_araucaniadiario
from services.file_export import guardar_en_csv, leer_desde_csv

# Constante para la zona horaria de Am√©rica/Santiago
TZ_SANTIAGO = pytz.timezone("America/Santiago")

MODELOS: list[str] = ["GEMINI", "OPENAI"]

def cargar_datos_a_db() -> None:
    """
    Carga los datos desde archivos CSV a la base de datos.
    """
    fecha_hora_actual = datetime.now(TZ_SANTIAGO)
    print(f"Fecha y hora actual en Santiago: {fecha_hora_actual}")

    diario_a: list[Noticia] = leer_desde_csv("noticias.csv")
    diario_b: list[Noticia] = leer_desde_csv("noticias2.csv")
    diarios_data: list[Noticia] = diario_a + diario_b

    print("Cargando datos desde los archivos CSV... üìÇ")

    for noticia in diarios_data:
        print(f"Guardado noticia: {noticia.titulo}")
        nueva_noticia = Noticia(
            titulo=noticia.titulo,
            fecha=fecha_hora_actual.strftime("%Y-%m-%d %H:%M:%S"),
            descripcion=noticia.descripcion,
            url=noticia.url,
            fuente=noticia.fuente
        )
        articulo_id = repository.insertar_articulo(nueva_noticia)
        if articulo_id:
            for modelo in MODELOS:
                repository.insertar_status(articulo_id=articulo_id, modelo=modelo, estado_procesado=False)
    print("Inserci√≥n de datos completada con √©xito üöÄ")

def obtener_datos_de_db(modelo: str) -> list[Article]:
    """
    Obtiene art√≠culos no procesados desde la base de datos para un modelo espec√≠fico.

    Par√°metros:
    - modelo: Nombre del modelo de IA para el cual se buscar√°n art√≠culos no procesados.

    Retorna:
    - Una lista de objetos Article que no han sido procesados (IS_PROCESSED = False) para el modelo especificado.
    """
    if modelo not in MODELOS:
        print(f"‚ö†Ô∏è El modelo '{modelo}' no es v√°lido. Modelos disponibles: {MODELOS}")
        return []

    try:
        articulos_modelo: list[Article] = repository.obtener_articulos_por_estado(modelo=modelo, estado_procesado=False)

        if articulos_modelo:
            print(f"‚úÖ Modelo: {modelo} - Art√≠culos no procesados: {len(articulos_modelo)}")
            return articulos_modelo

        print(f"‚ö†Ô∏è No se encontraron art√≠culos no procesados para el modelo '{modelo}'.")
        return []

    except Exception as e:
        print(f"‚ùå Error al obtener datos de la base de datos para el modelo '{modelo}': {e}")
        return []


def procesar_articulo_con_ia(articulo: Article, modelo: str) -> ProcessStatusDTO:
    """
    Procesa un art√≠culo con un modelo de IA espec√≠fico.
    """
    # Crear el prompt para el modelo
    print(f"articulo a procesar: '{articulo}'")
    titulo = articulo.titulo
    descripcion = articulo.descripcion
    prompt = f"""
    Analiza el siguiente art√≠culo de prensa y completa estrictamente los siguientes campos en formato JSON:

    Art√≠culo:
    "{titulo}"
    "{descripcion}"

    Devuelve tu respuesta en formato JSON respetando el siguiente esquema y sin ning√∫n comentario adicional(un json limpio):

    {{
        "etiquetas_ia": [ "etiqueta1", "etiqueta2", "..." ],
        "sentimiento": "positivo | negativo | neutro",
        "rating": "n√∫mero_decimal_entre_1.0_y_5.0_nivel_de_impacto",
        "nivel_riesgo": "bajo | medio | alto",
        "indicador_violencia": "s√≠ | no | moderado",
        "edad_recomendada": "+13 | +18 | todo p√∫blico"
    }}
    """

    # Crear instancia del servicio de IA
    modeloService = IAService(prompt=prompt)

    # Diccionario para el switch
    switch_modelos = {
        "GEMINI": modeloService.call_gemini,
        "OPENAI": modeloService.call_openAI,
    }

    # Llamar al m√©todo correspondiente seg√∫n el modelo
    if modelo in switch_modelos:
        data_procesada: ProcessStatusDTO = switch_modelos[modelo]()
    else:
        raise ValueError(f"Modelo '{modelo}' no soportado. Modelos disponibles: {list(switch_modelos.keys())}")

    print("ü§£ü§£ü§£")
    print(data_procesada)

    return data_procesada

def procesar_con_modelo_ia(articulos_no_procesados: list[Article], modelo: str) -> None:
    """
    Procesa los art√≠culos utilizando un modelo de IA, actualiza su estado en la base de datos
    y registra los resultados en la tabla de logs.
    """
    if not articulos_no_procesados:
        print("‚ö†Ô∏è No hay art√≠culos para procesar.")
        return

    print(f"‚úÖ Se encontraron {len(articulos_no_procesados)} art√≠culos no procesados. Procesando con IA...")

    for articulo in articulos_no_procesados:
        try:
            print(articulo)
            print(f"ü§ñ Procesando art√≠culo ID: {articulo.id}, T√≠tulo: {articulo.titulo}...")
            resultado_ia: ProcessStatusDTO = procesar_articulo_con_ia(articulo, modelo)

            procesado_exitosamente = (
                resultado_ia.status_code == 200 and resultado_ia.is_processed
            )

            if procesado_exitosamente:
                actualizado = repository.actualizar_datos_ia(articulo.id, resultado_ia)
                mensaje = "procesado y actualizado con √©xito" if actualizado else "procesado, pero no se pudo actualizar en la base de datos"
                print(f"‚úÖ Art√≠culo ID: {articulo.id} {mensaje}.")
            else:
                print(f"‚ö†Ô∏è Procesamiento fallido para el art√≠culo ID: {articulo.id}. C√≥digo de estado: {resultado_ia.status_code}")

            log_entry = IALogModel(
                article_id=articulo.id,
                model=resultado_ia.model_used,
                prompt="PROMPT SIMULADO",  # Reemplaza por el prompt real si lo tienes
                response="RESPUESTA SIMULADA",  # Reemplaza por la respuesta real si la tienes
                filtered_response=None,
                status_code=resultado_ia.status_code,
                response_time_sec=0.5,  # simulado
                tokens_used=100,        # simulado
                log_date=datetime.now(TZ_SANTIAGO)
            )
            repository.insertar_log(log_entry)

        except Exception as e:
            print(f"‚ùå Error al procesar el art√≠culo ID: {articulo.id}: {e}")
            # Registrar el error en el log
            log_entry = IALogModel(
                article_id=articulo.id,
                model=getattr(articulo, "model_name", "DESCONOCIDO"),
                prompt="PROMPT SIMULADO",
                response=f"ERROR: {str(e)}",
                filtered_response=None,
                status_code=500,
                response_time_sec=None,
                tokens_used=None,
                log_date=datetime.now(TZ_SANTIAGO)
            )
            repository.insertar_log(log_entry)
            continue

    print("üöÄ Procesamiento con modelo de IA completado.")


def procesar_datos() -> None:
    """
    Funci√≥n principal para procesar datos desde peri√≥dicos y realizar operaciones en la base de datos.
    """
    # Obtener informaci√≥n de peri√≥dicos
    #datos_diario_a: list[Noticia] = extraer_noticias_araucaniadiario(max_articulos=20)
    #datos_diario_b: list[Noticia] = extraer_noticias_elperiodico(max_articulos=20)

    # Guardar informaci√≥n en CSV
    #guardar_en_csv(datos_diario_a)
    #guardar_en_csv(datos_diario_b, nombre_archivo="noticias2.csv")

    # Cargar informaci√≥n hacia DB
    #cargar_datos_a_db()

    # Procesar datos con modelos de IA por cada modelo
    for modelo in MODELOS:
        articulos_no_procesados: list[Article] = obtener_datos_de_db(modelo)
        procesar_con_modelo_ia(articulos_no_procesados, modelo)